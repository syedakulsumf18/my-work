{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b0c21d",
   "metadata": {},
   "source": [
    "### Realtime Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e73ac4",
   "metadata": {},
   "source": [
    "Detects objects in realtime video streaming via webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0139b2",
   "metadata": {},
   "source": [
    "#### Import libraries for preprocessing and annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe01ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebdb08",
   "metadata": {},
   "source": [
    "#### Load pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638443d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\SYED WALI/.cache\\torch\\hub\\ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['numpy>=1.23.5', 'pillow>=10.3.0', 'requests>=2.32.0', 'tqdm>=4.64.0'] not found, attempting AutoUpdate...\n",
      "Collecting numpy>=1.23.5\n",
      "  Downloading numpy-2.0.0-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 60.9/60.9 kB ? eta 0:00:00\n",
      "Collecting pillow>=10.3.0\n",
      "  Downloading pillow-10.3.0-cp39-cp39-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting requests>=2.32.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.64.0\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from requests>=2.32.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from requests>=2.32.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from requests>=2.32.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from requests>=2.32.0) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from tqdm>=4.64.0) (0.4.6)\n",
      "Downloading numpy-2.0.0-cp39-cp39-win_amd64.whl (16.5 MB)\n",
      "   ---------------------------------------- 16.5/16.5 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading pillow-10.3.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 2.5/2.5 MB 9.0 MB/s eta 0:00:001\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 64.9/64.9 kB ? eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Installing collected packages: tqdm, requests, pillow, numpy\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.51.0\n",
      "    Uninstalling tqdm-4.51.0:\n",
      "      Successfully uninstalled tqdm-4.51.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 8.3.1\n",
      "    Uninstalling Pillow-8.3.1:\n",
      "      Successfully uninstalled Pillow-8.3.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Successfully installed numpy-2.0.0 pillow-10.3.0 requests-2.32.3 tqdm-4.66.4\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  21.4s, installed 4 packages: ['numpy>=1.23.5', 'pillow>=10.3.0', 'requests>=2.32.0', 'tqdm>=4.64.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-5-28 Python-3.9.8 torch-1.8.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1bd17",
   "metadata": {},
   "source": [
    "#### Run object detection on example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a0d6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ultralytics.com/images/zidane.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = ['https://ultralytics.com/images/zidane.jpg']\n",
    "Image(url=imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282e5a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.ImageFile' has no attribute 'PyEncoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m results\u001b[38;5;241m.\u001b[39mprint()\n\u001b[0;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[1;32mC:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:851\u001b[0m, in \u001b[0;36mAutoShape.forward\u001b[1;34m(self, ims, size, augment, profile)\u001b[0m\n\u001b[0;32m    849\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(im, (\u001b[38;5;28mstr\u001b[39m, Path)):  \u001b[38;5;66;03m# filename or uri\u001b[39;00m\n\u001b[1;32m--> 851\u001b[0m     im, f \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m, im\n\u001b[0;32m    852\u001b[0m     im \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exif_transpose(im))\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(im, Image\u001b[38;5;241m.\u001b[39mImage):  \u001b[38;5;66;03m# PIL Image\u001b[39;00m\n",
      "File \u001b[1;32mC:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages\\PIL\\Image.py:3012\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m   3010\u001b[0m         args \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m-> 3012\u001b[0m     im\u001b[38;5;241m.\u001b[39mfrombytes(data, decoder_name, args)\n\u001b[0;32m   3013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\n",
      "File \u001b[1;32mC:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages\\PIL\\Image.py:400\u001b[0m, in \u001b[0;36minit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    398\u001b[0m     decoder \u001b[38;5;241m=\u001b[39m DECODERS[decoder_name]\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder(mode, \u001b[38;5;241m*\u001b[39margs \u001b[38;5;241m+\u001b[39m extra)\n",
      "File \u001b[1;32mC:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages\\PIL\\BlpImagePlugin.py:418\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m BLPFormatError(msg)\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_as_raw(data)\n\u001b[1;32m--> 418\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBLPEncoder\u001b[39;00m(\u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyEncoder\u001b[49m):\n\u001b[0;32m    419\u001b[0m     _pushes_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_palette\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.ImageFile' has no attribute 'PyEncoder'"
     ]
    }
   ],
   "source": [
    "results = model(imgs)\n",
    "results.print()\n",
    "results.save(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='zidane.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0913e76",
   "metadata": {},
   "source": [
    "#### Run object detection on realtime video via webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Press q to exit the object detection window!\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, image_np = cap.read()\n",
    "    results = model(image_np)\n",
    "    df_result = results.pandas().xyxy[0]\n",
    "    dict_result = df_result.to_dict()\n",
    "    scores = list(dict_result[\"confidence\"].values())\n",
    "    labels = list(dict_result[\"name\"].values())\n",
    "    \n",
    "    list_boxes = list()\n",
    "    for dict_item in df_result.to_dict('records'):\n",
    "        list_boxes.append(list(dict_item.values())[:4])\n",
    "    count = 0\n",
    "    \n",
    "    for xmin, ymin, xmax, ymax in list_boxes:\n",
    "        image_np = cv2.rectangle(image_np, pt1=(int(xmin),int(ymin)), pt2=(int(xmax),int(ymax)), \\\n",
    "                                 color=(255,0, 0), thickness=2)\n",
    "        cv2.putText(image_np, f\"{labels[count]}: {round(scores[count], 2)}\", (int(xmin), int(ymin)-10), \\\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "        count = count + 1\n",
    "        \n",
    "    cv2.imshow('Object Detector', image_np);\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"The window has been exited!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac39d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from pyttsx3) (1.4.2)\n",
      "Requirement already satisfied: pypiwin32 in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\kandikits\\realtime-object-detection\\object-detection-env\\lib\\site-packages (from pyttsx3) (306)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397d419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\SYED WALI/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-5-28 Python-3.9.8 torch-1.8.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press q to exit the object detection window!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import pyttsx3\n",
    "import torch\n",
    "\n",
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Initialize pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "print(\"Press q to exit the object detection window!\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, image_np = cap.read()\n",
    "    results = model(image_np)\n",
    "    df_result = results.pandas().xyxy[0]\n",
    "    dict_result = df_result.to_dict()\n",
    "    scores = list(dict_result[\"confidence\"].values())\n",
    "    labels = list(dict_result[\"name\"].values())\n",
    "\n",
    "    list_boxes = []\n",
    "    for dict_item in df_result.to_dict('records'):\n",
    "        list_boxes.append(list(dict_item.values())[:4])\n",
    "    count = 0\n",
    "\n",
    "    for xmin, ymin, xmax, ymax in list_boxes:\n",
    "        image_np = cv2.rectangle(image_np, pt1=(int(xmin), int(ymin)), pt2=(int(xmax), int(ymax)),\n",
    "                                 color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(image_np, f\"{labels[count]}: {round(scores[count], 2)}\", (int(xmin), int(ymin) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "        # Speak out the detected object\n",
    "        engine.say(f\"I see {labels[count]}\")\n",
    "        engine.runAndWait()\n",
    "        count = count + 1\n",
    "\n",
    "    cv2.imshow('Object Detector', image_np)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"The window has been exited!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea4fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
